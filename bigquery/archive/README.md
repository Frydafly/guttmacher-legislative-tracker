# Archive Directory - Historical Migration Script

## Purpose

This directory contains the **completed historical migration script** that was used once to migrate 22 years of data (2002-2024) from Access databases to BigQuery.

## What's Here

- **`migrate.py`** - The monolithic historical migration script
  - ‚úÖ **STATUS**: Successfully completed migration of 2002-2024 data
  - ‚úÖ **PURPOSE SERVED**: Loaded 22+ years, ~22,000 bills into BigQuery
  - üö´ **DO NOT USE**: This script is retired and should not be run again

## Why It's Archived

### ‚úÖ Mission Accomplished
- Successfully migrated all historical data (2002-2024)
- Created harmonized schema across 22+ years  
- Built unified views and materialized tables
- Established field mappings and data quality tracking

### ‚ùå Wrong Tool for Ongoing Work
- **Overkill**: Re-processes ALL 22 years every time (takes ~90 minutes)
- **Monolithic**: One massive script doing everything
- **Historical focus**: Designed for one-time migration, not annual updates

## What to Use Instead

### For Annual Updates (2025, 2026, etc.)
```bash
# Use the new annual pipeline
python3 annual/add_year.py --year 2025
```

### For Data Analysis
```sql
-- Query the data that migrate.py created
SELECT * FROM `guttmacher-legislative-tracker.legislative_tracker_historical.all_historical_bills_unified`
```

## When You Might Reference This

### ‚úÖ Good Reasons to Look at `migrate.py`:
- **Understanding field mappings**: See how historical schema harmonization worked
- **Debugging data issues**: Check how specific edge cases were handled  
- **Learning from approach**: Reference for building similar migration scripts
- **Documenting decisions**: Understanding why certain choices were made

### ‚ùå Bad Reasons to Use `migrate.py`:
- Adding new years (use `annual/add_year.py` instead)
- Re-running migration (the data is already there!)
- Making schema changes (use the annual pipeline)

## The Bottom Line

**Think of this like a construction crew that built your house:**
- ‚úÖ The house is built and you live in it (the data is in BigQuery)  
- ‚úÖ You keep the blueprints for reference (the migration script is archived)
- ‚ùå You don't call the construction crew to add a new room (use the annual pipeline instead)

---

## Technical Note: Dependencies (Updated Dec 2025)

The script now intelligently searches for its dependencies in multiple locations:

**Configuration files:**
- Searches for `.env` in: `archive/.env` ‚Üí `bigquery/.env`
- Searches for `field_mappings.yaml` in: `archive/` ‚Üí `bigquery/` ‚Üí `bigquery/shared/`
- Searches for `data/` directory in: `archive/data` ‚Üí `bigquery/data`

**Sym links in place** (for convenience):
- `archive/.env` ‚Üí `bigquery/.env`
- `archive/field_mappings.yaml` ‚Üí `bigquery/field_mappings.yaml`
- `archive/data` ‚Üí `bigquery/data`

These symlinks exist so the script can run from either the `archive/` directory or the `bigquery/` directory. This makes recovery operations more flexible if ever needed again.

**If you need to run this (you shouldn't!):**
```bash
cd /path/to/bigquery
./setup_migration_env.sh  # Fix authentication
GCP_PROJECT_ID=guttmacher-legislative-tracker python3 archive/migrate.py
```

---

**This script served its purpose perfectly. It's kept for historical reference and learning, but should not be used for ongoing work.**